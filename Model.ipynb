{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Import Libraries"
      ],
      "metadata": {
        "id": "i1lbdHtNtmWL",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import copy\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "import re\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer, HashingVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import gensim\n",
        "from sklearn.metrics.pairwise import pairwise_distances_argmin\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import nltk"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "id": "IFw3LAOWtmWP",
        "colab_type": "code",
        "outputId": "79fef9da-a5d5-49df-c2ed-c4d603ae4993",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get data\n",
        "!wget 'https://raw.githubusercontent.com/xlogix/buddy-bot/master/data.zip'\n",
        "!unzip data.zip\n",
        "!mv data/dialogues.tsv ./dialogues.tsv\n",
        "!mv data/tagged_posts.tsv ./tagged_posts.tsv"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2020-01-15 17:14:44--  https://raw.githubusercontent.com/xlogix/buddy-bot/master/data.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 63453527 (61M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>]  60.51M   155MB/s    in 0.4s    \n",
            "\n",
            "2020-01-15 17:14:48 (155 MB/s) - ‘data.zip’ saved [63453527/63453527]\n",
            "\n",
            "Archive:  data.zip\n",
            "   creating: data/\n",
            "  inflating: data/dialogues.tsv      \n",
            "  inflating: data/tagged_posts.tsv   \n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "id": "9y2MLOX6IhjB",
        "colab_type": "code",
        "outputId": "b1c25097-93ce-44d5-c224-729859bebfc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data  data.zip\tdialogues.tsv  sample_data  tagged_posts.tsv\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "id": "5RgGYbfmu9q6",
        "colab_type": "code",
        "outputId": "a3ba29c5-e54f-4e66-a37e-691961ac1be2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Read the Data"
      ],
      "metadata": {
        "id": "QxWabwgutmWT",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dialogues = pd.read_csv(\"dialogues.tsv\",sep=\"\\t\")"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "qJ742017tmWU",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "posts = pd.read_csv(\"tagged_posts.tsv\",sep=\"\\t\")"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "4pl65BpptmWY",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dialogues.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Okay -- you're gonna need to learn how to lie.</td>\n",
              "      <td>dialogue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I'm kidding.  You know how sometimes you just ...</td>\n",
              "      <td>dialogue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Like my fear of wearing pastels?</td>\n",
              "      <td>dialogue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I figured you'd get to the good stuff eventually.</td>\n",
              "      <td>dialogue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Thank God!  If I had to hear one more story ab...</td>\n",
              "      <td>dialogue</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text       tag\n",
              "0     Okay -- you're gonna need to learn how to lie.  dialogue\n",
              "1  I'm kidding.  You know how sometimes you just ...  dialogue\n",
              "2                   Like my fear of wearing pastels?  dialogue\n",
              "3  I figured you'd get to the good stuff eventually.  dialogue\n",
              "4  Thank God!  If I had to hear one more story ab...  dialogue"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ],
      "execution_count": 6,
      "metadata": {
        "id": "VlE-7nZ2tmWb",
        "colab_type": "code",
        "outputId": "8d2e36de-86b1-4411-b87b-e5f60aa28fb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "posts.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>post_id</th>\n",
              "      <th>title</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9</td>\n",
              "      <td>Calculate age in C#</td>\n",
              "      <td>c#</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16</td>\n",
              "      <td>Filling a DataSet or DataTable from a LINQ que...</td>\n",
              "      <td>c#</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>39</td>\n",
              "      <td>Reliable timer in a console application</td>\n",
              "      <td>c#</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>42</td>\n",
              "      <td>Best way to allow plugins for a PHP application</td>\n",
              "      <td>php</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>59</td>\n",
              "      <td>How do I get a distinct, ordered list of names...</td>\n",
              "      <td>c#</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   post_id                                              title  tag\n",
              "0        9                                Calculate age in C#   c#\n",
              "1       16  Filling a DataSet or DataTable from a LINQ que...   c#\n",
              "2       39            Reliable timer in a console application   c#\n",
              "3       42    Best way to allow plugins for a PHP application  php\n",
              "4       59  How do I get a distinct, ordered list of names...   c#"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ],
      "execution_count": 7,
      "metadata": {
        "id": "ZwD7J2GqtmWh",
        "colab_type": "code",
        "outputId": "956fb4ab-79fa-4eeb-95ee-1f1bb852b4a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Num Posts:\",len(posts))\n",
        "print(\"Num Dialogues:\",len(dialogues))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num Posts: 2171575\n",
            "Num Dialogues: 218609\n"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {
        "id": "M9jPmFO9tmWl",
        "colab_type": "code",
        "outputId": "dd6d2789-7522-4472-af61-5efdd42d529d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Create training data for intent classifier - Chitchat/SO Question"
      ],
      "metadata": {
        "id": "D1LEJH4MtmWq",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts  =  list(dialogues[:200000].text.values) + list(posts[:200000].title.values)\n",
        "labels =  ['dialogue']*200000 + ['stackoverflow']*200000"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "PosZREB7tmWs",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame({'text':texts,'target':labels})"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "Gxb2RYUMtmWw",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_prepare(text):\n",
        "    \"\"\"Performs tokenization and simple preprocessing.\"\"\"\n",
        "    \n",
        "    replace_by_space_re = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "    bad_symbols_re = re.compile('[^0-9a-z #+_]')\n",
        "    stopwords_set = set(stopwords.words('english'))\n",
        "\n",
        "    text = text.lower()\n",
        "    text = replace_by_space_re.sub(' ', text)\n",
        "    text = bad_symbols_re.sub('', text)\n",
        "    text = ' '.join([x for x in text.split() if x and x not in stopwords_set])\n",
        "\n",
        "    return text.strip()"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "fq4FilpvtmWz",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Doing some data cleaning\n",
        "data['text'] = data['text'].apply(lambda x : text_prepare(x))"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "Aqzrqs80tmW4",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data['text'],data['target'],test_size = .1 , random_state=0)\n",
        "print('Train size = {}, test size = {}'.format(len(X_train), len(X_test)))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size = 360000, test size = 40000\n"
          ]
        }
      ],
      "execution_count": 13,
      "metadata": {
        "id": "4QFCwlWwtmW8",
        "colab_type": "code",
        "outputId": "44c11cdf-2ecf-4042-fe47-a2577654b376",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Create Intent classifier"
      ],
      "metadata": {
        "id": "Q7x1LtQttmW_",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We will keep our models and vectorizers in this folder"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "1vkMIu-4tmXA",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir resources"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "T-yUN2YvtmXD",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "def tfidf_features(X_train, X_test, vectorizer_path):\n",
        "    \"\"\"Performs TF-IDF transformation and dumps the model.\"\"\"\n",
        "    tfv = TfidfVectorizer(dtype=np.float32, min_df=3,  max_features=None, \n",
        "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
        "            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
        "            stop_words = 'english')\n",
        "    \n",
        "    X_train = tfv.fit_transform(X_train)\n",
        "    X_test = tfv.transform(X_test)\n",
        "    \n",
        "    pickle.dump(tfv,vectorizer_path)\n",
        "    return X_train, X_test\n",
        "'''"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": [
              "'\\ndef tfidf_features(X_train, X_test, vectorizer_path):\\n    \"\"\"Performs TF-IDF transformation and dumps the model.\"\"\"\\n    tfv = TfidfVectorizer(dtype=np.float32, min_df=3,  max_features=None, \\n            strip_accents=\\'unicode\\', analyzer=\\'word\\',token_pattern=r\\'\\\\w{1,}\\',\\n            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\\n            stop_words = \\'english\\')\\n    \\n    X_train = tfv.fit_transform(X_train)\\n    X_test = tfv.transform(X_test)\\n    \\n    pickle.dump(tfv,vectorizer_path)\\n    return X_train, X_test\\n'"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ],
      "execution_count": 16,
      "metadata": {
        "id": "QkP7QnfftmXM",
        "colab_type": "code",
        "outputId": "671eb3c8-f4ac-4c98-e25c-5c0c8fee1344",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "X_train_tfidf, X_test_tfidf = tfidf_features(X_train, X_test, open(\"resources/tfidf.pkl\",'wb'))\n",
        "'''"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": [
              "'\\nX_train_tfidf, X_test_tfidf = tfidf_features(X_train, X_test, open(\"resources/tfidf.pkl\",\\'wb\\'))\\n'"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ],
      "execution_count": 17,
      "metadata": {
        "id": "SQSa_6N_tmXP",
        "colab_type": "code",
        "outputId": "f9bf7c14-7ab1-49a1-df48-19cc15915d8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfv = TfidfVectorizer(dtype=np.float32, min_df=3,  max_features=None, \n",
        "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
        "            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
        "            stop_words = 'english')\n",
        "\n",
        "X_train = tfv.fit_transform(X_train)\n",
        "X_test = tfv.transform(X_test)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(360000, 124576)\n",
            "(40000, 124576)\n"
          ]
        }
      ],
      "execution_count": 18,
      "metadata": {
        "id": "IzqXTT6qNExT",
        "colab_type": "code",
        "outputId": "7a91d1f1-e9c9-47eb-c3b1-0ee35f9435bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initalizer model\n",
        "intent_recognizer = LogisticRegression(C=10,random_state=0, max_iter=2000)\n",
        "# save vectorizer inside model\n",
        "intent_recognizer._vectorizer = tfv"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "VYeriGvqOCwt",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# train\n",
        "intent_recognizer.fit(X_train_tfidf,y_train)\n",
        "'''"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/plain": [
              "'\\n# train\\nintent_recognizer.fit(X_train_tfidf,y_train)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ],
      "execution_count": 21,
      "metadata": {
        "id": "pDGETTPEtmXS",
        "colab_type": "code",
        "outputId": "e7824cbe-7029-49ad-a384-434bf6566c59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "intent_recognizer.fit(X_train,y_train)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 22,
          "data": {
            "text/plain": [
              "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=2000,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ],
      "execution_count": 22,
      "metadata": {
        "id": "0pbSDnrTOlC6",
        "colab_type": "code",
        "outputId": "5a5fb519-297e-4011-953d-d5cc0bd63e20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Check test accuracy.\n",
        "y_test_pred = intent_recognizer.predict(X_test_tfidf)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print('Test accuracy = {}'.format(test_accuracy))\n",
        "'''"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 23,
          "data": {
            "text/plain": [
              "\"\\n# Check test accuracy.\\ny_test_pred = intent_recognizer.predict(X_test_tfidf)\\ntest_accuracy = accuracy_score(y_test, y_test_pred)\\nprint('Test accuracy = {}'.format(test_accuracy))\\n\""
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ],
      "execution_count": 23,
      "metadata": {
        "id": "J-n6Uk2BtmXW",
        "colab_type": "code",
        "outputId": "906581d2-571b-4424-d45a-da80c7e7e328",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check test accuracy.\n",
        "y_test_pred = intent_recognizer.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print('Test accuracy = {}'.format(test_accuracy))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy = 0.98985\n"
          ]
        }
      ],
      "execution_count": 24,
      "metadata": {
        "id": "UwAM31HjOxZ9",
        "colab_type": "code",
        "outputId": "bb311380-ae73-4f7e-bc64-49ea9fdcdcfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dump model as well as _vectorizer\n",
        "pickle.dump(intent_recognizer, open(\"resources/intent_clf.pkl\" , 'wb'))"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "YM00eGlTtmXb",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 Create Programming Language classifier"
      ],
      "metadata": {
        "id": "K_kySOSItmXe",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = posts['title'].values\n",
        "y = posts['tag'].values"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "DTeXtzKftmXf",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "print('Train size = {}, test size = {}'.format(len(X_train), len(X_test)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size = 1737260, test size = 434315\n"
          ]
        }
      ],
      "execution_count": 27,
      "metadata": {
        "id": "bqGRMBWNtmXw",
        "colab_type": "code",
        "outputId": "1f0fa623-e3a1-4e41-fa7f-8f1bda7573d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "vectorizer = pickle.load(open(\"resources/tfidf.pkl\", 'rb'))\n",
        "X_train_tfidf, X_test_tfidf = vectorizer.transform(X_train), vectorizer.transform(X_test)\n",
        "'''"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "8PEWB4djtmXy",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "intent_recognizer = pickle.load(open('resources/intent_clf.pkl','rb'))\n",
        "vectorizer = intent_recognizer._vectorizer\n",
        "X_train_tfidf, X_test_tfidf = vectorizer.transform(X_train), vectorizer.transform(X_test)"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "ooHqdIBDPpbQ",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tag_classifier = OneVsRestClassifier(LogisticRegression(C=5,random_state=0, max_iter=2000))\n",
        "tag_classifier.fit(X_train_tfidf,y_train)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 29,
          "data": {
            "text/plain": [
              "OneVsRestClassifier(estimator=LogisticRegression(C=5, class_weight=None,\n",
              "                                                 dual=False, fit_intercept=True,\n",
              "                                                 intercept_scaling=1,\n",
              "                                                 l1_ratio=None, max_iter=2000,\n",
              "                                                 multi_class='auto',\n",
              "                                                 n_jobs=None, penalty='l2',\n",
              "                                                 random_state=0, solver='lbfgs',\n",
              "                                                 tol=0.0001, verbose=0,\n",
              "                                                 warm_start=False),\n",
              "                    n_jobs=None)"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ],
      "execution_count": 29,
      "metadata": {
        "id": "Ru3AZ1lCtmX1",
        "colab_type": "code",
        "outputId": "8ddd7433-3824-491d-ef06-2d99e94f21a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check test accuracy.\n",
        "y_test_pred = tag_classifier.predict(X_test_tfidf)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print('Test accuracy = {}'.format(test_accuracy))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy = 0.8043862173767887\n"
          ]
        }
      ],
      "execution_count": 30,
      "metadata": {
        "id": "3e5a-_qytmX4",
        "colab_type": "code",
        "outputId": "9b64fd91-919e-4661-e5b1-bea27f8d556a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "pickle.dump(tag_classifier, open(\"resources/tag_clf.pkl\", 'wb'))\n",
        "'''"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "PucS06IitmX6",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save vectorizer\n",
        "tag_classifier._vectorizer = vectorizer\n",
        "\n",
        "# save _vectorizer as well as model\n",
        "pickle.dump(tag_classifier, open(\"resources/tag_clf.pkl\", 'wb'))"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "ZrJHXiY8Q4PL",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 6. Store Question database Embeddings"
      ],
      "metadata": {
        "id": "hF7eKNJ-tmX8",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can use [pre-trained word vectors](https://code.google.com/archive/p/word2vec/) from Google."
      ],
      "metadata": {
        "id": "CsoHTvCGtmX9",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " !wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\"\n",
        " !gunzip \"GoogleNews-vectors-negative300.bin.gz\"\n",
        "\n",
        "# Load Google's pre-trained Word2Vec model.\n",
        "model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True) "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2020-01-15 17:54:10--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.129.85\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.129.85|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  11.6MB/s    in 2m 7s   \n",
            "\n",
            "2020-01-15 17:56:18 (12.4 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ]
        }
      ],
      "execution_count": 32,
      "metadata": {
        "id": "sB8fBjb9tmX9",
        "colab_type": "code",
        "outputId": "52b17657-ffec-41e6-fa48-e20ca8fa496b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to convert every question to an embedding and store them. Whenever user asks a stack overflow question we want to use cosine similarity to get the most similar question"
      ],
      "metadata": {
        "id": "_47wOlVEtmX_",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def question_to_vec(question, embeddings, dim=300):\n",
        "    \"\"\"\n",
        "        question: a string\n",
        "        embeddings: dict where the key is a word and a value is its' embedding\n",
        "        dim: size of the representation\n",
        "\n",
        "        result: vector representation for the question\n",
        "    \"\"\"\n",
        "    word_tokens = question.split(\" \")\n",
        "    question_len = len(word_tokens)\n",
        "    question_mat = np.zeros((question_len,dim), dtype = np.float32)\n",
        "    \n",
        "    for idx, word in enumerate(word_tokens):\n",
        "        if word in embeddings:\n",
        "            question_mat[idx,:] = embeddings[word]\n",
        "            \n",
        "    # remove zero-rows which stand for OOV words       \n",
        "    question_mat = question_mat[~np.all(question_mat == 0, axis = 1)]\n",
        "    \n",
        "    # Compute the mean of each word along the sentence\n",
        "    if question_mat.shape[0] > 0:\n",
        "        vec = np.array(np.mean(question_mat, axis = 0), dtype = np.float32).reshape((1,dim))\n",
        "    else:\n",
        "        vec = np.zeros((1,dim), dtype = np.float32)\n",
        "        \n",
        "    return vec"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "DUngX9MntmYA",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "counts_by_tag = posts.groupby(by=['tag'])[\"tag\"].count().reset_index(name = 'count').sort_values(['count'], ascending = False)"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "NORKwoNLtmYD",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "counts_by_tag = list(zip(counts_by_tag['tag'],counts_by_tag['count']))\n",
        "print(counts_by_tag)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('c#', 394451), ('java', 383456), ('javascript', 375867), ('php', 321752), ('c_cpp', 281300), ('python', 208607), ('ruby', 99930), ('r', 36359), ('vb', 35044), ('swift', 34809)]\n"
          ]
        }
      ],
      "execution_count": 36,
      "metadata": {
        "id": "1OoX-bTOtmYF",
        "colab_type": "code",
        "outputId": "77944f0b-e23f-459a-99b4-7bfb4a4b8fb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir resources/embeddings_folder"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "t4cEAIr9tmYH",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for tag, count in counts_by_tag:\n",
        "    tag_posts = posts[posts['tag'] == tag]\n",
        "    tag_post_ids = tag_posts['post_id'].values\n",
        "    tag_vectors = np.zeros((count, 300), dtype=np.float32)\n",
        "    for i, title in enumerate(tag_posts['title']):\n",
        "        tag_vectors[i, :] = question_to_vec(title, model, 300)\n",
        "    # Dump post ids and vectors to a file.\n",
        "    filename = 'resources/embeddings_folder/'+ tag + '.pkl'\n",
        "    pickle.dump((tag_post_ids, tag_vectors), open(filename, 'wb'))"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "23RVI7XstmYK",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Given a question and tag can I retrieve the most similar question post_id\n"
      ],
      "metadata": {
        "id": "zTWftvFCtmYM",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_similar_question(question,tag):\n",
        "    # get the path where all question embeddings are kept and load the post_ids and post_embeddings\n",
        "    embeddings_path = 'resources/embeddings_folder/' + tag + \".pkl\"\n",
        "    post_ids, post_embeddings = pickle.load(open(embeddings_path, 'rb'))\n",
        "    # Get the embeddings for the question\n",
        "    question_vec = question_to_vec(question, model, 300)\n",
        "    # find index of most similar post\n",
        "    best_post_index = pairwise_distances_argmin(question_vec,\n",
        "                                                post_embeddings)\n",
        "    # return best post id\n",
        "    return post_ids[best_post_index]"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "je9rXuz5tmYN",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_similar_question(\"how to use list comprehension in python?\",'python')"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 40,
          "data": {
            "text/plain": [
              "array([5947137])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ],
      "execution_count": 40,
      "metadata": {
        "id": "y9WZnu4BtmYO",
        "colab_type": "code",
        "outputId": "10b42cad-aa2e-4987-cab7-5b1adc5a7636",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can find this question at:\n",
        "    \n",
        "https://stackoverflow.com/questions/5947137"
      ],
      "metadata": {
        "id": "7OYcALhgtmYR",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Try and Test it out!\n"
      ],
      "metadata": {
        "colab_type": "text",
        "id": "9GvE_nErYjoo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### Install dependencies\n",
        "!pip install chatterbot\n",
        "!pip install chatterbot-corpus"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "9kLkG6tSbEp3",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\n",
        "import requests\n",
        "import time\n",
        "import argparse\n",
        "import os\n",
        "import json\n",
        "from requests.compat import urljoin\n",
        "import gensim\n",
        "import pickle\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import pairwise_distances_argmin\n",
        "\n",
        "\n",
        "class BotHandler(object):\n",
        "    \"\"\"\n",
        "        BotHandler is a class which implements all back-end of the bot.\n",
        "        It has three main functions:\n",
        "            'get_updates' — checks for new messages\n",
        "            'send_message' – posts new message to user\n",
        "            'get_answer' — computes the most relevant on a user's question\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, token, dialogue_manager):\n",
        "        # Put the Telegram Access token here\n",
        "        self.token = token\n",
        "        self.api_url = \"https://api.telegram.org/bot{}/\".format(token)\n",
        "        self.dialogue_manager = dialogue_manager\n",
        "\n",
        "    def get_updates(self, offset=None, timeout=30):\n",
        "        params = {\"timeout\": timeout, \"offset\": offset}\n",
        "        raw_resp = requests.get(urljoin(self.api_url, \"getUpdates\"), params)\n",
        "        try:\n",
        "            resp = raw_resp.json()\n",
        "        except json.decoder.JSONDecodeError as e:\n",
        "            print(\"Failed to parse response {}: {}.\".format(raw_resp.content, e))\n",
        "            return []\n",
        "\n",
        "        if \"result\" not in resp:\n",
        "            return []\n",
        "        return resp[\"result\"]\n",
        "\n",
        "    def send_message(self, chat_id, text):\n",
        "        params = {\"chat_id\": chat_id, \"text\": text}\n",
        "        return requests.post(urljoin(self.api_url, \"sendMessage\"), params)\n",
        "\n",
        "    def get_answer(self, question):\n",
        "        if question == '/start':\n",
        "            return \"Hi, I am your project bot. How can I help you today?\"\n",
        "        return self.dialogue_manager.generate_answer(question)\n",
        "\n",
        "\n",
        "def is_unicode(text):\n",
        "    return len(text) == len(text.encode())\n",
        "\n",
        "\n",
        "# We will need this function to prepare text at prediction time\n",
        "def text_prepare(text):\n",
        "    \"\"\"Performs tokenization and simple preprocessing.\"\"\"\n",
        "\n",
        "    replace_by_space_re = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "    bad_symbols_re = re.compile('[^0-9a-z #+_]')\n",
        "    stopwords_set = set(stopwords.words('english'))\n",
        "\n",
        "    text = text.lower()\n",
        "    text = replace_by_space_re.sub(' ', text)\n",
        "    text = bad_symbols_re.sub('', text)\n",
        "    text = ' '.join([x for x in text.split() if x and x not in stopwords_set])\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "# need this to convert questions asked by user to vectors\n",
        "\n",
        "\n",
        "def question_to_vec(question, embeddings, dim=300):\n",
        "    \"\"\"\n",
        "        question: a string\n",
        "        embeddings: dict where the key is a word and a value is its' embedding\n",
        "        dim: size of the representation\n",
        "        result: vector representation for the question\n",
        "    \"\"\"\n",
        "    word_tokens = question.split(\" \")\n",
        "    question_len = len(word_tokens)\n",
        "    question_mat = np.zeros((question_len, dim), dtype=np.float32)\n",
        "\n",
        "    for idx, word in enumerate(word_tokens):\n",
        "        if word in embeddings:\n",
        "            question_mat[idx, :] = embeddings[word]\n",
        "\n",
        "    # remove zero-rows which stand for OOV words\n",
        "    question_mat = question_mat[~np.all(question_mat == 0, axis=1)]\n",
        "\n",
        "    # Compute the mean of each word along the sentence\n",
        "    if question_mat.shape[0] > 0:\n",
        "        vec = np.array(np.mean(question_mat, axis=0),\n",
        "                       dtype=np.float32).reshape((1, dim))\n",
        "    else:\n",
        "        vec = np.zeros((1, dim), dtype=np.float32)\n",
        "\n",
        "    return vec\n",
        "\n",
        "\n",
        "class SimpleDialogueManager(object):\n",
        "    \"\"\"\n",
        "    This is a simple dialogue manager to test the telegram bot.\n",
        "    The main part of our bot will be written here.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        # Instantiate all the models and TFIDF Objects.\n",
        "        print(\"Loading resources...\")\n",
        "        # Instantiate a Chatterbot for Chitchat type questions\n",
        "        from chatterbot import ChatBot\n",
        "        from chatterbot.trainers import ChatterBotCorpusTrainer\n",
        "        chatbot = ChatBot('ZoeyChatterbot')\n",
        "        trainer = ChatterBotCorpusTrainer(chatbot)\n",
        "        trainer.train('chatterbot.corpus.english')\n",
        "        self.chitchat_bot = chatbot\n",
        "        print(\"Loading Word2vec model...\")\n",
        "        # Instantiate the Google's pre-trained Word2Vec model.\n",
        "        self.model = gensim.models.KeyedVectors.load_word2vec_format(\n",
        "            'GoogleNews-vectors-negative300.bin', binary=True)\n",
        "        print(\"Loading Classifier objects...\")\n",
        "        # Load the intent classifier and tag classifier\n",
        "        self.intent_recognizer = pickle.load(\n",
        "            open('resources/intent_clf.pkl', 'rb'))\n",
        "        self.tag_classifier = pickle.load(open('resources/tag_clf.pkl', 'rb'))\n",
        "        # Load the TFIDF vectorizer object\n",
        "        self.tfidf_vectorizer = self.tag_classifier._vectorizer\n",
        "        print(\"Finished Loading Resources\")\n",
        "\n",
        "    # We created this function just above. We just need to have a function to get most similar question's *post id* in the dataset given we know the programming Language of the question. Here it is:\n",
        "    def get_similar_question(self, question, tag):\n",
        "        # get the path where all question embeddings are kept and load the post_ids and post_embeddings\n",
        "        embeddings_path = 'resources/embeddings_folder/' + tag + \".pkl\"\n",
        "        post_ids, post_embeddings = pickle.load(open(embeddings_path, 'rb'))\n",
        "        # Get the embeddings for the question\n",
        "        question_vec = question_to_vec(question, self.model, 300)\n",
        "        # find index of most similar post\n",
        "        best_post_index = pairwise_distances_argmin(question_vec,\n",
        "                                                    post_embeddings)\n",
        "        # return best post id\n",
        "        return post_ids[best_post_index]\n",
        "\n",
        "    def generate_answer(self, question):\n",
        "        prepared_question = text_prepare(question)\n",
        "        features = self.tfidf_vectorizer.transform([prepared_question])\n",
        "        # find intent\n",
        "        intent = self.intent_recognizer.predict(features)[0]\n",
        "        # Chit-chat part:\n",
        "        if intent == 'dialogue':\n",
        "            response = self.chitchat_bot.get_response(question)\n",
        "        # Stack Overflow Question\n",
        "        else:\n",
        "            # find programming language\n",
        "            tag = self.tag_classifier.predict(features)[0]\n",
        "            # find most similar question post id\n",
        "            post_id = self.get_similar_question(question, tag)[0]\n",
        "            # respond with\n",
        "            response = 'I think its about %s\\nThis thread might help you: https://stackoverflow.com/questions/%s' % (\n",
        "                tag, post_id)\n",
        "        return response\n",
        "\n",
        "\n",
        "def main():\n",
        "    token = '999394784:AAGG2PY_F49Z2w39oxY3wcjZ6P_LQP9tsag'\n",
        "    simple_manager = SimpleDialogueManager()\n",
        "    bot = BotHandler(token, simple_manager)\n",
        "    ###############################################################\n",
        "\n",
        "    print(\"Ready to talk!\")\n",
        "    offset = 0\n",
        "    while True:\n",
        "        updates = bot.get_updates(offset=offset)\n",
        "        for update in updates:\n",
        "            print(\"An update received.\")\n",
        "            if \"message\" in update:\n",
        "                chat_id = update[\"message\"][\"chat\"][\"id\"]\n",
        "                if \"text\" in update[\"message\"]:\n",
        "                    text = update[\"message\"][\"text\"]\n",
        "                    if is_unicode(text):\n",
        "                        print(\"Update content: {}\".format(update))\n",
        "                        bot.send_message(chat_id, bot.get_answer(\n",
        "                            update[\"message\"][\"text\"]))\n",
        "                    else:\n",
        "                        bot.send_message(\n",
        "                            chat_id, \"Hmm, you are sending some weird characters to me...\")\n",
        "            offset = max(offset, update['update_id'] + 1)\n",
        "        time.sleep(1)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading resources...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Training ai.yml: [####################] 100%\n",
            "\n",
            "Training computers.yml: [####################] 100%\n",
            "Training conversations.yml: [####################] 100%\n",
            "Training emotion.yml: [####################] 100%\n",
            "Training food.yml: [####################] 100%\n",
            "Training gossip.yml: [####################] 100%\n",
            "Training greetings.yml: [####################] 100%\n",
            "Training health.yml: [####################] 100%\n",
            "Training history.yml: [####################] 100%\n",
            "Training humor.yml: [####################] 100%\n",
            "Training literature.yml: [####################] 100%\n",
            "Training money.yml: [####################] 100%\n",
            "Training movies.yml: [####################] 100%\n",
            "\n",
            "Training psychology.yml: [####################] 100%\n",
            "\n",
            "Training sports.yml: [####################] 100%\n",
            "Training trivia.yml: [####################] 100%\n",
            "Loading Word2vec model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Classifier objects...\n",
            "Finished Loading Resources\n",
            "Ready to talk!\n",
            "An update received.\n",
            "Update content: {'update_id': 937061020, 'message': {'message_id': 218, 'from': {'id': 794766696, 'is_bot': False, 'first_name': 'Anah Veronica', 'last_name': 'Immanuel', 'language_code': 'en'}, 'chat': {'id': 794766696, 'first_name': 'Anah Veronica', 'last_name': 'Immanuel', 'type': 'private'}, 'date': 1579106455, 'text': 'Remove NA values'}}\n",
            "An update received.\n",
            "Update content: {'update_id': 937061021, 'message': {'message_id': 219, 'from': {'id': 794766696, 'is_bot': False, 'first_name': 'Anah Veronica', 'last_name': 'Immanuel', 'language_code': 'en'}, 'chat': {'id': 794766696, 'first_name': 'Anah Veronica', 'last_name': 'Immanuel', 'type': 'private'}, 'date': 1579106474, 'text': '/start', 'entities': [{'offset': 0, 'length': 6, 'type': 'bot_command'}]}}\n",
            "An update received.\n",
            "Update content: {'update_id': 937061022, 'message': {'message_id': 220, 'from': {'id': 794766696, 'is_bot': False, 'first_name': 'Anah Veronica', 'last_name': 'Immanuel', 'language_code': 'en'}, 'chat': {'id': 794766696, 'first_name': 'Anah Veronica', 'last_name': 'Immanuel', 'type': 'private'}, 'date': 1579106510, 'text': 'Hello'}}\n",
            "An update received.\n",
            "Update content: {'update_id': 937061023, 'message': {'message_id': 221, 'from': {'id': 417649667, 'is_bot': False, 'first_name': 'Abhi', 'username': 'abhishekuniyal', 'language_code': 'en'}, 'chat': {'id': 417649667, 'first_name': 'Abhi', 'username': 'abhishekuniyal', 'type': 'private'}, 'date': 1579106713, 'text': '/start', 'entities': [{'offset': 0, 'length': 6, 'type': 'bot_command'}]}}\n",
            "An update received.\n",
            "Update content: {'update_id': 937061024, 'message': {'message_id': 222, 'from': {'id': 417649667, 'is_bot': False, 'first_name': 'Abhi', 'username': 'abhishekuniyal', 'language_code': 'en'}, 'chat': {'id': 417649667, 'first_name': 'Abhi', 'username': 'abhishekuniyal', 'type': 'private'}, 'date': 1579108394, 'text': '/start', 'entities': [{'offset': 0, 'length': 6, 'type': 'bot_command'}]}}\n"
          ]
        }
      ],
      "execution_count": 0,
      "metadata": {
        "id": "NPQFcqpOa5S4",
        "colab_type": "code",
        "outputId": "b14e7508-815f-4533-f1b3-ad78d0398dbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 811
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "7y7uFxipa8TV",
        "colab_type": "code",
        "colab": {}
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "Model.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "K_kySOSItmXe",
        "hF7eKNJ-tmX8",
        "zTWftvFCtmYM"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "nteract": {
      "version": "0.15.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}